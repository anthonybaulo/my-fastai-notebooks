{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can use the standard library gzip to open it and then we can pickle.load() it. So in Python the kind of standard serialization format is called pickle, and so this MNIST version on deeplearning.net is stored in that format, so it basically gives us a tuple of tuple of datasets like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually contains numpy arrays, but numpy arrays are not allowed in our foundations. So we have to convert them into tensors. So we can just use the Python map to map the tensor function over each of these four arrays, so we get back four tensors.\n",
    "\n",
    "A lot of you will be more familiar with numpy arrays than PyTorch tensors, but you know, everything you can do in numpy arrays you can also do in PyTorch tensors, but you can also do it on the GPU and have all this nice deep learning infrastructure. So it is a good idea to get used to using PyTorch tensors in my opinion.\n",
    "\n",
    "So we can now grab the numbers of rows and number of columns in the training set and we can take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "n,c = x_train.shape\n",
    "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here's MNIST, hopefully pretty familiar to you already. It is 50000 rows by 784 columns (28px x 28px), and the y data looks something like this: the y_shape is just 50000 rows and the minimum and maximum of the dependent variable is 0 - 9. Hopefully that looks pretty familiar.\n",
    "\n",
    "So let's add some tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n==y_train.shape[0]==50000\n",
    "test_eq(c,28*28)\n",
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got a FloatTensor and we pass that to imshow() after casting it to a 28 by 28. .view() is really important, I think we saw it a few times in part one, but get really familiar with it this is how we reshape our 784 long vector into a 28 by 28 matrix that is suitable for plotting.\n",
    "\n",
    "Ok, so there's our data. And let's start by creating a simple linear model.\n",
    "So for a linear model we are going to need to basically have something where y = ax + b and so our a will be a bunch of weights, so it is needs to be a 784 by 10 matrix, because we got 784 coming in and 10 coming out. That is going to allow us take in our independent variable and map it to something which we can compare to our dependent variable. And for our bias we just start with 10 zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication with loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar, ac = a.shape\n",
    "    br, bc = b.shape\n",
    "    \n",
    "    # make sure matrices can be multiplied\n",
    "    assert ac==br          \n",
    "    \n",
    "    # init c to zeros with correct shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    \n",
    "    # loop thru n_rows of a\n",
    "    # loop thru n_cols of b\n",
    "    # loop thru n_cols of a, or n_rows of b\n",
    "    # update c\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_valid[:5]    # first 5 from valid set\n",
    "m2 = weights        # torch.randn(784,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 884 ms, sys: 0 ns, total: 884 ms\n",
      "Wall time: 891 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is all the same (the first 7 lines). But now we have replaced the inner loop and you'll see that basically it loks exactly the same as before but where it used to say k it now says :. \n",
    "\n",
    "So in PyTorch and numpy : means the entirity of that axis. So Rachel help me remember the order of rows and columns when we talk about matrices, which is the song 'Row by column, row by column'. So i is the row number, take all cloumns (a[i,:]). And this (b[:,j]) is column number j, take all rows. So multiply all of column j by all of row i and that gives us back a rank one tensor, which we add up. \n",
    "\n",
    "Ok, that is exactly the same as what we had before. So now that takes 1.45ms. We have removed one line of code and it is a 178 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    # Fill in code here\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c[i]` is the same as `c[i,:]`. Any time there's a trailing colon in numpy or PyTorch, you can delete it optionally. You don't have to. \n",
    "\n",
    "`c[None,:]` is the same as `c[None]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matmul with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    # Code here\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are going to set the whole of row i of c (`c[i]`) to the whole of row i of a (`a[i]`) turned into a rank two tensor: (`a[i].unsqueeze(-1)`) We could also have written it like that (`a[i, None]`)<br>\n",
    "So this is now of length `ar` by 1, which is a rank two tensor. b is also a rank two tensor, and that is the entirity of our matrix.\n",
    "\n",
    "And so `a[i].unsqueeze(-1)` is going to get broadcast over this `b`. Which gets rid of the loop.\n",
    "\n",
    "This is actually going to return a rank two tensor. And then that rank to tensor we want to sum it up over the rows `sum(dim=0)`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
